{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 손실 함수\n",
    "### 4.2.1 오차제곱합(sum of squares for error, SSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_squares_error(y, t):\n",
    "    return 0.5 * np.sum((y-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09750000000000003\n",
      "0.5975\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 정답은 '2'\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "# 예1 : '2'일 확률이 가장 높다고 추정함 (0.6)\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "\n",
    "print(sum_squares_error(np.array(y), np.array(t)))\n",
    "\n",
    "# 예2 : '7'일 확률이 가장 높다고 추정함 (0.6)\n",
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "\n",
    "print(sum_squares_error(np.array(y), np.array(t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 교차 엔트로피 오차(cross entropy error, CEE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    delta = 1e-7    # np.log에 0을 입력하면 -inf가 되어 계산 진행 불가. 이를 방지.\n",
    "    return -np.sum(t * np.log(y + delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.510825457099338\n",
      "2.302584092994546\n"
     ]
    }
   ],
   "source": [
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "print(cross_entropy_error(np.array(y), np.array(t)))\n",
    "\n",
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "print(cross_entropy_error(np.array(y), np.array(t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 미니배치 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir) # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "from mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(one_hot_label=True, normalize=False)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32714  5696 49951 58873 21604 43873 15428 17018 17012 19176]\n"
     ]
    }
   ],
   "source": [
    "print(np.random.choice(60000, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.4 (배치용) 교차 엔트로피 오차 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 레이블(t)이 원-핫 인코딩일 경우\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t * np.log(y + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 레이블이 원-핫 인코딩이 아닐 경우\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
    "\n",
    "# 원-핫 인코딩일 때 t가 0인 원소는 교차 엔트로피 오차도 0이므로 그 계산을 무시하는 것."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.5 왜 손실 함수를 설정하는가?\n",
    "신경망을 학습할 때 정확도를 지표로 삼으면, 매개변수의 미분이 대부분의 장소에서 0이 되기 때문에 이를 신경망 학습의 지표로 삼으면 안된다. 정확도는 매개변수의 미소한 변화에는 거의 반응을 보이지 않고, 반응이 있더라도 그 값이 불연속적으로 갑자기 변화한다. 이는 '계단 함수'를 활성화 함수로 사용하지 않는 이유와도 들어맞는다. 반면 시그모이드 함수는 미분이 어느 장소라도 0이 되지 않는다.\n",
    "\n",
    "## 4.3 수치 미분\n",
    "### 4.3.1 미분 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나쁜 구현 예\n",
    "def numerical_diff(f, x):\n",
    "    h = 1e-50\n",
    "    return (f(x+h)-f(x)) / h\n",
    "\n",
    "# 1e-50은 너무 작아서 반올림오차(rounding error)를 일으킴. 10^(-4) 정도로도 충분\n",
    "# 진정한 의미의 접선과 이 구현값은 엄밀히는 일치하지 않음. 한계점임.\n",
    "# 따라서 이를 보완하기 위해 전방차분 대신 중심차분(중앙차분) 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_diff(f, x):\n",
    "    h = 1e-4 # 0.0001\n",
    "    return (f(x+h)-f(x-h)) / (2*h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 수치 미분의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(x):\n",
    "    return 0.01*x**2 + 0.1*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEGCAYAAABvtY4XAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAiF0lEQVR4nO3deXhV1b3/8feXhDCEMQMzAcIkgyAYSFBKnYtcKmrVgkWKMmirVnqv9Xprf9ZW77WD9Wq1taKgIKPzgCPOUiEQIIwBEoYQpgyMgUBCkvX7I4dexAQDZGefc/J5PU+enJy9T9aXffb5sLP22mubcw4REQk/9fwuQEREvKGAFxEJUwp4EZEwpYAXEQlTCngRkTAV6XcBJ4uLi3OdO3f2uwwRkZCxfPnyAudcfGXLgirgO3fuTFpamt9liIiEDDPLrmqZumhERMKUAl5EJEwp4EVEwpSnAW9mLczsVTPbYGYZZjbEy/ZEROT/eH2S9UngA+fcDWYWBTT2uD0REQnwLODNrDkwDBgP4JwrAUq8ak9ERL7Jyy6aLkA+8IKZrTSz580s2sP2RETkJF4GfCQwEHjGOTcAOALcf+pKZjbZzNLMLC0/P9/DckREgs/y7H089+UWT363lwG/A9jhnEsN/PwqFYH/Dc65qc65JOdcUnx8pRdjiYiEpYzdh7j1hWXMTs3mSHFpjf9+zwLeObcHyDGznoGnLgfWe9WeiEgo2VZwhFumLaVxVCQvTUgmukHNnxL1ehTN3cDswAiaLcCtHrcnIhL09hw8xthpqZSVlzNv8hA6xngzwNDTgHfOpQNJXrYhIhJKDhSVMG56KvuPlDB3cgrdWjX1rK2gmmxMRCScHSkuZfwLy9i2t4gXbx1Evw4tPG1PUxWIiNSCY8fLmDgjjTU7D/L0mAFc1DXO8zYV8CIiHispLefns1ewZOte/nJjf67q06ZW2lXAi4h4qKzc8cv56Xy6IY//vvZ8rh3QvtbaVsCLiHikvNzxn6+t5t01u3lgRC9uTk6o1fYV8CIiHnDO8bt31vHq8h3cc3l3Jg1LrPUaFPAiIh7484cbmbE4m4lDuzDliu6+1KCAFxGpYX/7LIu/f76ZMYMTeODfemFmvtShgBcRqUEv/nMrf/5wI6MuaMcj1/b1LdxBAS8iUmNeTsvhoXfWc2Xv1jx2Y38i6vkX7qCAFxGpEQtW7+L+11bzve5xPH3zAOpH+B+v/lcgIhLiPt2Qy5R56VzYqSXP3nIhDSIj/C4JUMCLiJyTrzLzuWPWCnq1bca08YNoHBU8U3wp4EVEztLXmwuYOCONxLhoZt42mGYN6/td0jco4EVEzsLSrfuY8GIaCTGNmT0xmZbRUX6X9C0KeBGRM7Q8ez+3vrCUti0aMntSMrFNGvhdUqUU8CIiZ2BVzgHGT19KfNMGzJ2UQqumDf0uqUoKeBGRalq78yC3TEulRXR95kxKoXWz4A13UMCLiFRLxu5DjJ2WStOG9ZkzMYV2LRr5XdJ3UsCLiHyHzNxCxj6fSsPICOZMSvbsJtk1TQEvInIam/MPM+a5VOrVM+ZMSqZTbLTfJVWbAl5EpArbCo5w83NLAMfcSckkxjfxu6QzooAXEalEzr4ibn5uCSWl5cyemEK3Vk39LumMBc81tSIiQSJnXxGjpy7hSEkZcyYl07NN6IU7KOBFRL5h+94iRk9dzJGSMmZPTKZPu+Z+l3TWPA14M9sGFAJlQKlzLsnL9kREzkX23iOMmbqEouMV4d63feiGO9TOEfylzrmCWmhHROSsbSs4wpjnlnDseBlzJqbQu10zv0s6Z+qiEZE6b2tBxZF7SVk5cyal0Ktt6Ic7eD+KxgEfmdlyM5tc2QpmNtnM0swsLT8/3+NyRES+aUv+YUZPXRwI9+SwCXfwPuCHOucGAlcDd5rZsFNXcM5Ndc4lOeeS4uPjPS5HROT/bM4/zOipSygtc8ydlMJ5bcIn3MHjgHfO7Qx8zwPeAAZ72Z6ISHVl5VWEe7lzzJ2cErJDIU/Hs4A3s2gza3riMXAVsNar9kREqisrr5DRU5fgHMydlEKP1uEX7uDtSdbWwBtmdqKdOc65DzxsT0TkO2XmFjLmuSWYGXMnpdCtVWhNP3AmPAt459wWoL9Xv19E5Ext3FPIT56vG+EOmotGROqItTsP8uOpi4moZ8ybHP7hDgp4EakDlmfvZ8xzS4iOiuTl24fQNcRmhTxbutBJRMLa4s17mTBjGa2aNmD2pBTah8CdmGqKAl5EwtYXm/KZPDONhJjGzJ6YTKsgv4dqTVPAi0hYWrg+lztnr6BrqybMmjCY2CYN/C6p1ingRSTsLFi9iynz0unTvjkzbx1M88b1/S7JFzrJKiJh5bXlO/jF3JUMSGjBrAl1N9xBR/AiEkZmp2bzwBtrubhbLM+NS6JxVN2OuLr9rxeRsDFt0VYeXrCey85rxd9/MpCG9SP8Lsl3CngRCXl/+yyLP3+4kav7tuHJ0QOIilTvMyjgRSSEOef4wwcbePaLLVx7QTseu7E/kREK9xMU8CISksrKHb95cw1zl+YwNiWB31/Tl3r1zO+ygooCXkRCTklpOb98OZ13V+/mzku7cu9VPQnMXCsnUcCLSEg5WlLGHbOW88WmfH494jwmD+vqd0lBSwEvIiHj4NHjTHhxGSu27+ePPzqfHw9K8LukoKaAF5GQkF9YzLjpS8nKK+Tpmwcy4vy2fpcU9BTwIhL0duwvYuzzqeQeKmbaTwcxrEe83yWFBAW8iAS1rLxCxj6/lKKSUmZNTObCTi39LilkKOBFJGit3nGAn05fSkS9esy/fQi92jbzu6SQooAXkaC0ZMteJs5Io0Xj+syakEznuGi/Swo5CngRCTrvr9nNPfPT6RTTmJcmJNOmed26UUdNUcCLSFB5aUk2D761lgEdWzB9/CBaNI7yu6SQpYAXkaDgnOPxhZt46tMsrujViqfGDKRRlGaEPBcKeBHxXWlZOb95cy3zluXw46SO/Pd1fTVpWA3wPODNLAJIA3Y650Z63Z6IhJajJWXcPXclH2fkcvdl3fj3K3toXpkaUhtH8PcAGYDGN4nINxwoKmHCjDRWbN/Pw6P6cMuQzn6XFFY8/RvIzDoA/wY872U7IhJ6dh04yg3/WMyaHQf5+80DFe4e8PoI/gngPqBpVSuY2WRgMkBCgiYOEqkLNuUWMm7aUo4UlzJzwmBSEmP9LikseXYEb2YjgTzn3PLTreecm+qcS3LOJcXHa34JkXC3bNs+bnjma8qd4+U7hijcPeTlEfzFwDVmNgJoCDQzs1nOubEetikiQeyDtXu4Z95K2rdsxMzbBtOhZWO/Swprnh3BO+f+yznXwTnXGRgNfKpwF6m7pi3ays9mL6d3u2a8esdFCvdaoHHwIuKpsnLHwwvW8+LX2xjepw1PjL6AhvV1AVNtqJWAd859DnxeG22JSPA4WlLGL+atZOH6XCYM7cKvR/QiQjfGrjU6ghcRT+QXFjNxxjJW7zzIQz/szfiLu/hdUp2jgBeRGrc5/zDjX1hKfmExz469kKv6tPG7pDpJAS8iNWrp1n1MmplG/Qhj3uQhXNCxhd8l1VkKeBGpMW+v2sW9L6+iQ0wjXhw/mIRYjZTxkwJeRM6Zc45nvtjMnz7YyOAuMUy95ULN4x4EFPAick6Ol5Xz4FvrmLt0O9f0b8efb+xHg0gNgwwGCngROWsHi45z55wVLMoq4GeXdOVXV/WknoZBBg0FvIiclW0FR7htxjJy9hXxpxv6cVNSR79LklMo4EXkjC3evJefza6YR3DWhGSSNWFYUFLAi8gZmb9sOw+8sZZOsY2ZPn4QnWKj/S5JqqCAF5FqKSt3/PGDDUz9cgvf6x7H0zcPpHmj+n6XJaehgBeR73S4uJQp81bycUYe44Z04sGRvXVT7BCggBeR09p54CgTXlxGZt5hfj+qD+N0a72QoYAXkSqt2L6fyTOXU3y8jBfGD2JYD911LZQo4EWkUm+l7+RXr66mTbOGzJ2UTPfWVd5aWYKUAl5EvqGs3PHnDzfyjy82M7hzDP+45UJiojXtQChSwIvIvxw8epx75q3k84353JycwEM/7ENUpE6mhioFvIgAkJV3mEkz08jZV8Qj1/ZlbEonv0uSc6SAFxE+ychlyrx0oiLrMWdSCoO7xPhdktQABbxIHeac4++fb+axjzbSp10znr0lifYtGvldltQQBbxIHVVUUsqvXlnNu2t2M+qCdvzh+n40itI0v+FEAS9SB+XsK2LSzDQ25Rby6xHnMel7iZhpmt9wo4AXqWO+3lzAnbNXUFbueOHWwXxfFy+FLQW8SB3hnOOFf27jv9/LoEtcNM+NS6JLnGaCDGeeBbyZNQS+BBoE2nnVOfdbr9oTkaodKS7l/tfX8M6qXVzZuzWP39Sfpg01E2S48/IIvhi4zDl32MzqA4vM7H3n3BIP2xSRU2zOP8wdLy1nc/5h7hvekzuGddVt9eoIzwLeOeeAw4Ef6we+nFftici3fbB2D/e+soqoyHq8NCGZi7vF+V2S1KLvvAbZzO42s5Zn88vNLMLM0oE8YKFzLrWSdSabWZqZpeXn559NMyJyitKych59P4M7Zi2na6smLLh7qMK9DqrOJBOtgWVm9rKZDbczGEvlnCtzzl0AdAAGm1nfStaZ6pxLcs4lxcfrbL7IuSo4XMwt05by7BdbGJuSwMu3p9BOFy/VSd8Z8M653wDdgWnAeCDTzP7HzLpWtxHn3AHgM2D42ZUpItWxYvt+Rv51ESu27+exG/vzyLXn0yBSFy/VVdWaJi7Qn74n8FUKtAReNbM/VfUaM4s3sxaBx42AK4EN51qwiHybc46Zi7fx42cXUz/SeP3nF3HDhR38Lkt89p0nWc3sHmAcUAA8D/zKOXfczOoBmcB9Vby0LTDDzCKo+I/kZefcgpopW0ROKCop5TdvrOX1lTu57LxW/O9NF9C8sYZASvVG0cQA1zvnsk9+0jlXbmYjq3qRc241MOAc6xOR08jMLeTns1eQlX+Yf7+yB3dd2k1DIOVfvjPgT3dxknMuo2bLEZHqem35Dn7z5lqiG0Tw0m3JDO2uUTLyTZqqQCTEHC0p48G31vLK8h2kJMbw19EDaNWsod9lSRBSwIuEkKy8ii6ZzLzD/OKybtxzRQ8i1CUjVVDAi4SI11fs4IE31tI4KoKZtw3me9113YicngJeJMgdLSnjobfXMT8th+QuMfx1zABaq0tGqkEBLxLEsvIKuXP2SjblFXL3Zd245/LuREZU6/IVEQW8SDByzjF/WQ4PvbOO6KhIZtw6mGG6MYecIQW8SJA5ePQ4v359De+u2c3QbnE8flN/jZKRs6KAFwkiadv2cc+8dHIPHeP+q89j8vcSdeGSnDUFvEgQKCt3/O2zLJ74eBMdYxrz6s8u4oKOLfwuS0KcAl7EZ7sOHGXK/HSWbt3HdQPa8/tRfXQ7PakRCngRH32wdg//+dpqSsvKefym/lw/UDNASs1RwIv4oKiklEfezWBO6nbOb9+cv44ZQJe4aL/LkjCjgBepZek5B/jl/HS27T3C7cMS+Y+rehIVqbHtUvMU8CK1pLSsnKc/y+KpT7No06whcyelkJIY63dZEsYU8CK1YGvBEabMT2dVzgGuG9Ce343qQzOdSBWPKeBFPOScY+7SHB5esJ6oyHo8ffMARvZr53dZUkco4EU8kl9YzP2vreaTDXkM7RbHYzf2p01zXZEqtUcBL+KBhetzuf+11RQWl/LgyN6Mv6izrkiVWqeAF6lBB4uO87sF63h9xU56tW3G3NEX0KN1U7/LkjpKAS9SQz7bmMf9r62m4HAJv7isG3dd1l3DH8VXCniRc1R47DiPLMhgfloO3Vs14blxSfTr0MLvskQU8CLnYlFmAfe9uoo9h45xx/e7MuWK7jSsH+F3WSKAAl7krBwpLuXR9zOYtWQ7ifHRvPqzixiY0NLvskS+wbOAN7OOwEygNeCAqc65J71qT6S2LNmyl1+9uood+48ycWgX7v1BTx21S1Dy8gi+FPgP59wKM2sKLDezhc659R62KeKZwmPH+cP7G5idup1OsY15+fYhDOoc43dZIlXyLOCdc7uB3YHHhWaWAbQHFPAScj7JyOU3b64l99AxJg7twr9f1YPGUerhlOBWK3uomXUGBgCplSybDEwGSEhIqI1yRKpt7+FifvfOet5etYuerZvyzNgLdaclCRmeB7yZNQFeA6Y45w6dutw5NxWYCpCUlOS8rkekOpxzvJW+i9+9s47DxaX88ooe/OySrhrXLiHF04A3s/pUhPts59zrXrYlUlN2HTjKA2+s4bON+QxIaMEff9RPV6NKSPJyFI0B04AM59zjXrUjUlPKyx2zU7P5w/sbKHfw4Mje/PSizkRoDhkJUV4ewV8M3AKsMbP0wHO/ds6952GbImclY/chfv3GGlZuP8DQbnE8ev35dIxp7HdZIufEy1E0iwAd+khQKyop5YmPM5m2aCstGtXn8Zv6c92A9lT8ASoS2jTOS+qsj9fn8tu317HzwFFGD+rI/VefR4vGUX6XJVJjFPBS5+w+eJSH3l7Hh+ty6dG6Ca/coQuWJDwp4KXOKC0rZ8bibB7/aCNlznHf8J5MHJqooY8SthTwUies3L6f//fWWtbuPMQlPeN5eFRfnUSVsKeAl7C293Axf/xgAy+n7aBV0wb87eaBjDi/jU6iSp2ggJewVFpWzuzU7fzlo40UlZRx+7BE7r68O00aaJeXukN7u4SdZdv28eBb68jYfYih3eJ46Jo+dGvVxO+yRGqdAl7CRt6hYzz6/gbeWLmTds0b8sxPBjK8r7pjpO5SwEvIO15Wzoyvt/HEx5mUlJZz16Xd+PmlXTWdr9R5+gRIyHLO8dnGPB55N4Mt+Ue4pGc8v/1hH7rERftdmkhQUMBLSNqUW8jDC9bzVWYBiXHRPD8uict7tVJ3jMhJFPASUvYdKeF/F25iztLtREdF8P9G9uaWlE66WEmkEgp4CQklpeXMXLyNJz/JpKikjLHJCUy5ogctozV3jEhVFPAS1JxzLFyfy/+8l8G2vUVc0jOeB0b0ortuwCHynRTwErRW5Rzg0fczWLJlH91aNeGFWwdxac9WfpclEjIU8BJ0svce4U8fbuTd1buJjY7i96P6MGZwAvUj1M8uciYU8BI0Cg4X89QnmcxO3U79iHr84rJuTBqWSNOG9f0uTSQkKeDFd0UlpTz/1VamfrmFo8fL+PGgjky5vDutmjX0uzSRkKaAF9+UlpUzPy2HJz7OJL+wmB/0ac19w8+ja7zmjRGpCQp4qXXl5Y531+zmfz/exJb8IyR1ask/xg7kwk66q5JITVLAS605MeTx8YWb2LCnkB6tmzD1lgu5sndrXYEq4gEFvHjOOcdXmQX85aONrNpxkC5x0Tw5+gJG9mtHRD0Fu4hXFPDiqdQte/nLR5tYum0f7Vs04k839OP6Ae2J1JBHEc8p4MUT6TkH+MtHG/kqs4BWTRvw8Kg+3DSoIw0iI/wuTaTOUMBLjVqevZ+nPs3k8435xERH8cCIXoxN6USjKAW7SG3zLODNbDowEshzzvX1qh0JDqlb9vLUp1ksyiogJjqK+4b3ZNyQzroHqoiPvPz0vQg8Dcz0sA3xkXOOxZv38uQnmaRu3UdckwY8MKIXP0lJ0N2URIKAZ59C59yXZtbZq98v/jkxKuavn2SSlr2f1s0a8Nsf9mbM4AQa1ldXjEiw8P0wy8wmA5MBEhISfK5GTqe83LEwI5dnPt9Mes4B2jVvyMOj+nBjUkcFu0gQ8j3gnXNTgakASUlJzudypBLFpWW8uXInz365hS35R+gY04hHrz+fHw3soDspiQQx3wNeglfhsePMSd3O9H9uJfdQMX3aNeOpMQO4um8bjWMXCQEKePmWvMJjvPDPbcxakk3hsVIu7hbLYzf2Z2i3OE0pIBJCvBwmORe4BIgzsx3Ab51z07xqT87d5vzDPP/VVl5bsYPjZeWM6NuW27+fSL8OLfwuTUTOgpejaMZ49bul5jjnWJRVwPRFW/lsYz5RkfX40cAOTB6WSJe4aL/LE5FzoC6aOurY8YoTp9P/uZVNuYeJa9KAX17Rg5uTE4hv2sDv8kSkBijg65i8Q8d4aUk2s1O3s+9ICb3bNuOxG/vzw/5tNU+MSJhRwNcRq3IO8OLX21iwehel5Y4re7XmtqFdSO4SoxOnImFKAR/GjpaU8c6qXcxKzWb1joNER0UwNqUT4y/qTKdY9a+LhDsFfBjakn+Y2anbeSUth0PHSunRugkPj+rDtQPa07Rhfb/LE5FaooAPE6Vl5XyckcusJdtZlFVA/QhjeN+2jE1OYLC6YUTqJAV8iNuxv4hX0nYwf1kOew4do13zhtx7VQ9uGtSRVk0b+l2eiPhIAR+CikvL+GhdLi+n5bAoqwCAod3i+P2oPlx2XitNIyAigAI+pGTsPsT8ZTm8mb6TA0XHad+iEb+4rDs3JnWgQ8vGfpcnIkFGAR/kDh07ztvpu3g5LYfVOw4SFVGPK/u05sdJHbm4WxwR9dS3LiKVU8AHoZLScr7clM8b6Tv5eH0uxaXlnNemKQ+O7M11A9rTMjrK7xJFJAQo4IOEc46VOQd4c+VO3lm1i/1Fx4mJjmL0oI5cP7AD/To010gYETkjCnifbS04wpsrd/Jm+k6y9xbRILIeV/ZuzXUD2jOsRzz1dcJURM6SAt4Huw4c5b01u1mwejfpOQcwgyGJsdx1aTeG922ji5FEpEYo4GvJ7oNHeW/NHt5dvYsV2w8A0LttM/7r6vO45oJ2tG3eyN8CRSTsKOA9tOfgMd5bs5t31+xmefZ+oCLUf/WDnow4v63mWxcRTynga9i2giMsXJ/Lh+v2kBYI9V5tm3HvVT0YcX5bEuOb+FyhiNQVCvhzVF7uSN9xgIXrc/l4fS6ZeYeBilD/jyt7MKJfW7oq1EXEBwr4s3DseBlfby6oCPWMPPILi4moZyR3ieHm5ASu6NWajjG6slRE/KWAr6acfUV8sSmfzzfm8/XmAopKyoiOiuCSnq24sndrLu3ZiuaNNfpFRIKHAr4Kx46Xkbp1H19szOfzTXlsyT8CQIeWjbh+YHuu6NWaIV1jdZs7EQlaCvgA5xyb8w/zVWYBn2/MZ8mWvRSXlhMVWY+UxFjGJnfi+z3jSYyL1hWlIhIS6mzAO+fYvq+IxZv38vXmvSzespf8wmIAEuOiGTM4gUt6xpPcJZZGUTpKF5HQU6cCfvfBo3ydVRHmizfvZeeBowDEN23AkMRYLuoay0Vd40iI1QlSEQl9nga8mQ0HngQigOedc3/wsr2TlZc7MvMOk5a9j+Xb9pOWvZ/t+4oAaNm4PimJsdzx/USGdI2la3wTdbuISNjxLODNLAL4G3AlsANYZmZvO+fWe9He0ZIy0nMOsDx7H2nZ+1mRvZ9Dx0oBiGsSxYWdWjJuSCcu6hrHeW2aUk/zqItImPPyCH4wkOWc2wJgZvOAUUCNBnxxaRk3PbuEdTsPUlruAOjeqgn/1q8tF3aKIalTSzrFNtYRuojUOV4GfHsg56SfdwDJp65kZpOByQAJCQln3EiDyAi6xDbm4q6xJHVuycCElrRorBtiiIj4fpLVOTcVmAqQlJTkzuZ3PDF6QI3WJCISDry8m8ROoONJP3cIPCciIrXAy4BfBnQ3sy5mFgWMBt72sD0RETmJZ100zrlSM7sL+JCKYZLTnXPrvGpPRES+ydM+eOfce8B7XrYhIiKV0x2dRUTClAJeRCRMKeBFRMKUAl5EJEyZc2d1bZEnzCwfyD7Ll8cBBTVYTk1RXWcuWGtTXWdGdZ25s6mtk3MuvrIFQRXw58LM0pxzSX7XcSrVdeaCtTbVdWZU15mr6drURSMiEqYU8CIiYSqcAn6q3wVUQXWduWCtTXWdGdV15mq0trDpgxcRkW8KpyN4ERE5iQJeRCRMhVzAm9lwM9toZllmdn8lyxuY2fzA8lQz61wLNXU0s8/MbL2ZrTOzeypZ5xIzO2hm6YGvB72uK9DuNjNbE2gzrZLlZmZ/DWyv1WY2sBZq6nnSdkg3s0NmNuWUdWpte5nZdDPLM7O1Jz0XY2YLzSwz8L1lFa/9aWCdTDP7aS3U9Wcz2xB4r94wsxZVvPa077sHdT1kZjtPer9GVPHa035+Pahr/kk1bTOz9Cpe6+X2qjQfamUfc86FzBcV0w5vBhKBKGAV0PuUdX4O/CPweDQwvxbqagsMDDxuCmyqpK5LgAU+bLNtQNxplo8A3gcMSAFSfXhP91BxsYYv2wsYBgwE1p703J+A+wOP7wf+WMnrYoAtge8tA49belzXVUBk4PEfK6urOu+7B3U9BNxbjff6tJ/fmq7rlOV/AR70YXtVmg+1sY+F2hH8v27k7ZwrAU7cyPtko4AZgcevApebx3fcds7tds6tCDwuBDKouCdtKBgFzHQVlgAtzKxtLbZ/ObDZOXe2VzCfM+fcl8C+U54+eT+aAVxbyUt/ACx0zu1zzu0HFgLDvazLOfeRc6408OMSKu6UVquq2F7VUZ3Pryd1BTLgJmBuTbVXXafJB8/3sVAL+Mpu5H1qkP5rncAH4SAQWyvVAYEuoQFAaiWLh5jZKjN738z61FJJDvjIzJZbxQ3OT1Wdbeql0VT9ofNje53Q2jm3O/B4D9C6knX83na3UfHXV2W+6333wl2BrqPpVXQ3+Lm9vgfkOucyq1heK9vrlHzwfB8LtYAPambWBHgNmOKcO3TK4hVUdEP0B54C3qylsoY65wYCVwN3mtmwWmr3O1nFrRyvAV6pZLFf2+tbXMXfykE1ntjMHgBKgdlVrFLb7/szQFfgAmA3Fd0hwWQMpz9693x7nS4fvNrHQi3gq3Mj73+tY2aRQHNgr9eFmVl9Kt682c65109d7pw75Jw7HHj8HlDfzOK8rss5tzPwPQ94g4o/k0/m583RrwZWOOdyT13g1/Y6Se6JrqrA97xK1vFl25nZeGAk8JNAMHxLNd73GuWcy3XOlTnnyoHnqmjPr+0VCVwPzK9qHa+3VxX54Pk+FmoBX50beb8NnDjTfAPwaVUfgpoS6N+bBmQ45x6vYp02J84FmNlgKra9p//xmFm0mTU98ZiKE3RrT1ntbWCcVUgBDp70Z6PXqjyq8mN7neLk/einwFuVrPMhcJWZtQx0SVwVeM4zZjYcuA+4xjlXVMU61Xnfa7quk8/bXFdFe9X5/HrhCmCDc25HZQu93l6nyQfv9zEvzhp7+UXFqI9NVJyNfyDw3O+p2OEBGlLxJ38WsBRIrIWahlLx59VqID3wNQK4A7gjsM5dwDoqRg4sAS6qhboSA+2tCrR9YnudXJcBfwtszzVAUi29j9FUBHbzk57zZXtR8Z/MbuA4FX2cE6g4b/MJkAl8DMQE1k0Cnj/ptbcF9rUs4NZaqCuLij7ZE/vZiRFj7YD3Tve+e1zXS4H9ZzUVwdX21LoCP3/r8+tlXYHnXzyxX520bm1ur6rywfN9TFMViIiEqVDrohERkWpSwIuIhCkFvIhImFLAi4iEKQW8iEiYUsCLiIQpBbyISJhSwItUwcwGBSbPahi42nGdmfX1uy6R6tKFTiKnYWaPUHF1dCNgh3PuUZ9LEqk2BbzIaQTmTFkGHKNiuoQyn0sSqTZ10YicXizQhIo78TT0uRaRM6IjeJHTMLO3qbjzUBcqJtC6y+eSRKot0u8CRIKVmY0Djjvn5phZBPC1mV3mnPvU79pEqkNH8CIiYUp98CIiYUoBLyISphTwIiJhSgEvIhKmFPAiImFKAS8iEqYU8CIiYer/A46MvXC2X3m7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "x = np.arange(0.0, 20.0, 0.1) # 0에서 20까지 0.1 간격의 배열 x를 만든다(20 미포함)\n",
    "y = function_1(x)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1999999999990898\n",
      "0.2999999999986347\n"
     ]
    }
   ],
   "source": [
    "print(numerical_diff(function_1, 5))\n",
    "print(numerical_diff(function_1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3 편미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2\n",
    "# 또는 return np.sum(x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.00000000000378"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_0 = 3, x_1 = 4 일 때, x_0에 대한 편미분은?\n",
    "\n",
    "def function_tmp1(x0):\n",
    "    return x0*x0 + 4.0**2.0\n",
    "\n",
    "numerical_diff(function_tmp1, 3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 기울기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x) # x와 형상이 같은 배열을 생성\n",
    "    \n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        # f(x+h) 계산\n",
    "        x[idx] = tmp_val + h\n",
    "        fxh1 = f(x)\n",
    "        \n",
    "        # f(x-h) 계산\n",
    "        x[idx] = tmp_val - h\n",
    "        fxh2 = f(x)\n",
    "        \n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        x[idx] = tmp_val # 값 복원\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6. 8.]\n",
      "[0. 4.]\n",
      "[6. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(numerical_gradient(function_2, np.array([3.0, 4.0])))\n",
    "print(numerical_gradient(function_2, np.array([0.0, 2.0])))\n",
    "print(numerical_gradient(function_2, np.array([3.0, 0.0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 기울기가 가리키는 쪽은 각 장소에서 함수의 출력 값을 가장 크게 줄이는 방향임! </b>\n",
    "\n",
    "### 4.4.1 경사법(경사 하강법)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "    \n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= lr*grad\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.11110793e-10  8.14814391e-10]\n"
     ]
    }
   ],
   "source": [
    "init_x = np.array([-3.0, 4.0])\n",
    "print(gradient_descent(function_2, init_x = init_x, lr=0.1, step_num=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.58983747e+13 -1.29524862e+12]\n"
     ]
    }
   ],
   "source": [
    "# 학습률이 너무 큰 예\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "print(gradient_descent(function_2, init_x = init_x, lr=10.0, step_num=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.99400594  3.99200791]\n"
     ]
    }
   ],
   "source": [
    "init_x = np.array([-3.0, 4.0])\n",
    "print(gradient_descent(function_2, init_x = init_x, lr=1e-5, step_num=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2 신경망에서의 기울기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "from common.functions import softmax, cross_entropy_error\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class simpleNet:\n",
    "    def __init__(self):\n",
    "        self.W = np.random.randn(2, 3) # 정규분포로 초기화\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.16898761 -0.11004477  1.2382047 ]\n",
      " [-0.33239157  1.88181042  1.31480292]]\n",
      "[-0.19775985  1.62760251  1.92624544]\n",
      "2\n",
      "0.6213158513862862\n"
     ]
    }
   ],
   "source": [
    "net = simpleNet()\n",
    "print(net.W) # 가중치 매개변수\n",
    "\n",
    "x = np.array([0.6, 0.9])\n",
    "p = net.predict(x)\n",
    "print(p)\n",
    "\n",
    "print(np.argmax(p)) # 최댓값의 인덱스\n",
    "\n",
    "t = np.array([0, 0, 1]) # 정답 레이블\n",
    "print(net.loss(x, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03853659  0.23912119 -0.27765778]\n",
      " [ 0.05780488  0.35868179 -0.41648667]]\n"
     ]
    }
   ],
   "source": [
    "def f(W):\n",
    "    return net.loss(x, t)\n",
    "\n",
    "dW = numerical_gradient(f, net.W)\n",
    "print(dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda w: net.loss(x, t)\n",
    "dW = numerical_gradient(f, net.W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 학습 알고리즘 구현하기\n",
    "### 4.5.1 2층 신경망 클래스 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from common.functions import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class TwoLayerNet:\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "    \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "        \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        return cross_entropy_error(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "        \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 100)\n",
      "(100,)\n",
      "(100, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "net = TwoLayerNet(input_size=784, hidden_size=100, output_size=10)\n",
    "print(net.params['W1'].shape)\n",
    "print(net.params['b1'].shape)\n",
    "print(net.params['W2'].shape)\n",
    "print(net.params['b2'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-c7fa5221bc26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 더미 정답 레이블(100장 분량)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 기울기 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-164823f4b53d>\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/Python-Deep-Learning/src/Deep Learning from Scratch 1/common/gradient.py\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[0;34m(f, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mtmp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mfxh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# f(x+h)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_val\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-164823f4b53d>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(W)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# x : 입력 데이터, t : 정답 레이블\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mloss_W\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-164823f4b53d>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# x : 입력 데이터, t : 정답 레이블\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcross_entropy_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-164823f4b53d>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0ma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x = np.random.rand(100, 784) # 더미 입력 데이터(100장 분량)\n",
    "t = np.random.rand(100, 10) # 더미 정답 레이블(100장 분량)\n",
    "\n",
    "grads = net.numerical_gradient(x, t) # 기울기 계산\n",
    "print(grads['W1'].shape)\n",
    "print(grads['b1'].shape)\n",
    "print(grads['W2'].shape)\n",
    "print(grads['b2'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.2 미니배치 학습 구현하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "train_loss_list = []\n",
    "\n",
    "# 하이퍼파라미터\n",
    "iters_num = 10000 # 반복횟수\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100 # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "\n",
    "network = TwoLayerNet(input_size = 784, hidden_size = 50, output_size=10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 기울기 계산\n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    # grad = network.gradient(x_batch, t_batch) # 성능 개선판!\n",
    "    \n",
    "    # 매개변수 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    print(i, '번째 학습')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
